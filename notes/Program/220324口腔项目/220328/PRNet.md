# PRNet: Self-Supervised Learning for Partial-to-Partial Registration

## 摘要

作者提出了一种简单、灵活、通用的点云配准框架，成为部分配准网络（Partial Registration Network, PRNet），用于部分到部分的点云配准。作者使用深度网络来解决排列的非凸性以及部分对应问题。

## 一、介绍

配准是预测将一个点云与另一个点云对齐的刚性运动的问题。  
最近，PointNetLK和Deep Closest Point（DCP）表明基于学习的配准方法可以比经典方法更快、更健壮。然而，这些方法不能处理部分到部分配准。

作者提出的部分配准网络（PRNet），是一个连续决策框架，用以解决一大类配准问题。与ICP类似，该方法被设计为使用迭代策略，能够对初始配准估计从粗到精进行精细化。该框架的一个重要新组建是关键点检测子模块，它能够根据共同的上下文信息识别输入点云中匹配的点。然后部分到部分点云配准可以归结为检测两个点云共有的关键点，将这些关键点彼此匹配，解决Procrustes问题

> Procrustes是一种通过分析形状分布，比较两组数据一致性的方法。数学上来讲，就是不断迭代，寻找标准形状，并利用最小二乘法存照每个对象形状到这个标准形状的仿射变化方法。该过程也称为最小二乘正交映射。

由于PRNet被设计为使用迭代策略，作者使用Gumbel-Softmax和直通梯度估计来确定采样关键点的对应关系。这种新的架构和学习过程重新调整了匹配的清晰度，PRNet中远距离点云可以使用漫反射（模糊）匹配进行粗略匹配，而最终的精细化迭代更倾向于使用更清晰的地图。相对于引入另一个超参数，PRNet决定使用子网络来预测Gumbel-Softmax对应的温度，这可以看作是Actor-Critor的简化版，也就是说，PRNet会在每次应用时都会学习调整地图清晰度的级别。

论文的主要贡献：
* 提出了部分配准网络（PRNet），它使用具有最先进的深度网络来实现部分到部分点云的配准
* 使用Gumbel-Softmax和直通梯度估计来获取尖锐和近似可微的映射函数
* 设计了Actor-Critor最近点模块，使用动作网络和价值网络来调节对应的锐度。与固定参数的可微方法相比，该模块可以预测更准确的刚性变换
* 展示了配准是学习3D形状表示的一个有用的代理任务，该表示可以转移到其他任务，包括关键点检测、对应预测和形状分类
* 为了进一步研究，作者发布了源码

## 二、相关工作
## 三、方法

3.1介绍刚性对齐问题以及相关算法的初步知识，3.2介绍PRNet

### 3.1准备：配准、ICP以及DCP

考虑两个点云X和Y，刚性配准的基本任务是找到能够严格对齐的旋转 $ R_{xy} $ 和平移 $ t_{xy} $。当M=N时，ICP和它的同行通过最小化目标函数来实现这一任务

$$ E(R_{xy},t_{xy},m) = \frac{1}{N} \sum_{i=1}^{N} || R_{xy}x_{i} + t_{xy} -y_{m(x_i)} || ^ 2 (1)$$

这里，刚性变换由一对 $ [R_{xy},t_{xy}] $ 定义， m是茨贝格点集X到点击Y的映射。假如映射是固定的，上面公式中的对齐可以近似为：

$$ R_{xy} = VU^{\top} $$
$$ t_{xy} = -R_{xy} \bar{x} + \bar{y} (2)$$

而ICP以及基于学习的DCP方法可以理解为提供了不同选择的m

***Iterative Closest Point*** ICP在$ [R_{xy},t_{xy}] $固定的情况下，选择m来最小化（1）

$$ m(x_i,y) = argmin_j || R_{xy}x_i + t_{xy} - y_i ||_2 (3)$$

ICP方法在(2)和(3)之间交替逼近一个固定点，每一步都减少目标(1)，但由于(1)是非凸的，不能保证得到全局最优解

***Deep Closest Point*** DCP使用深度网络去学习m，在这个方法中，使用DGCNN定义的学习函数 $ F_x $ 和 $ F_y $ 对 X 和 Y 进行嵌入。这些点云可以选择性地通过Transformer模块进行上下文化，产生嵌入 $ \Phi_x $ 和 $ \Phi_y $。映射m为：

$$ m(x_i,y) = softmax(\Phi_y\Phi_{x_i}^{\top}) (4)$$

该公式在公式(2)之后使用一次来获得刚性对齐。用于训练地损失函数为合成旋转点云的真实刚性运动与预测之间的均方差（MSE）

### 3.2局部配准网络

DCP是一次性算法，因为网络的一次传递决定了每个预测任务的输出。与ICP类似，PRNet被设计为迭代的，点云通过PRNet的多次遍历优化对齐。如图1所示，PRNet的步骤如下：

1. 以点云X、Y作为输入
2. 检查X和Y的关键点
3. 预测从X的关键点到Y的关键点的映射
4. 基于关键点和映射预测从X到Y的刚性变化 $ [R_{xy},t_{xy}] $ 
5. 使用得到的变换来变换X
6. 将 $ R_{xy}x + t_{xy},y $作为输入回到步骤1

由于作者的训练对是综合生成的，在应用PRNet之前，我们知道$ [R_{xy}^*,t_{xy}^*] $ 的真实值。根据这些值，在训练期间，可以动态地计算“局部”真实值$ [R_{xy}^{p*},t_{xy}^{p*}] $，将当前 $ (x_p,y) $映射到最佳对齐。

这里使用 $ m^p $ 表示步骤p时的映射

综上以上表述，$ x^p $ 可以通过一下公式给出：

$$ x_i^p = R_{xy}^{p-1}x_i^{p-1} + t_{xy}^{p-1} $$
其中
$$ R_{xy}^p = V^pU^{p\top} $$
$$ t_{xy}^p = -R_{xy}^p\bar{x}^p + \bar{y} $$

***关键点检测*** 对于局部对局部配准，通常$ N\neq{M} $ 并且只有X和Y的子集与另一个进行匹配。为了检测相互共享的部分，作者设计了一个简单高效的关键点检测模块，该模块使用L2范数来观察某个点是否重要

使用 $ x_k^p $ 和 $ y_k^p $ 表示 $ x^p $ 和 $ y^p $ 的k个关键点：
$$ x_k^p = x^p(topk(||\Phi_{x_1}^p||_2,...,||\Phi_{x_i}^p||_2,...,||\Phi_{x_N}^p||_2)) $$
$$ y_k^p = y^p(topk(||\Phi_{y_1}^p||_2,...,||\Phi_{y_i}^p||_2,...,||\Phi_{y_M}^p||_2)) $$

其中，topk(·)提取给定输入的k个最大元素的索引。这里的$ \Phi $ 是DGCNN和Transformer学习到的嵌入

***Gumbel-Softmax采样*** 从ICP和DCP中可以发现，公式(3)对于映射m是不可微的，但根据定义，点集X和Y中的点之间存在明显的对应。相反，在DCP中的光滑函数(4)是可微的，但作为交换，映射变得模糊。但作者想要两全其美，找到潜在的能够反向传播的尖锐映射函数

为此，作者使用Gumbel-Softmax对匹配矩阵进行采样，使用直通梯度估计，该模块是近似可微的。Gumbel-Softmax映射函数由下式给出：

$$ m^p(x_i,y) = onehot[argmax_j softmax(\Phi_y^p \Phi_{x_i}^{p\top} + g_{ij})] (10)$$

其中，$(g_{i1},...,g_{ij},...,g_{iN})$ 是取自Gumbel的i个样本。由于argmax的不连续性，(10)中的映射是不连续的，但是直通梯度估计产生具有低方差（有方差）的次梯度估计。

***Actor-Critor最近点（ACP）*** 映射函数(4)(10)拥有固定的“温度”，也就是说，不能控制映射矩阵$m^p$的锐度，在PRNet中，作者希望能够根据两个形状的对齐来调整映射的锐度。对于较低的p（初始迭代），可以满足获得粗对比的高熵近似匹配，在后续迭代中，可以锐化映射来对齐单独的点对

为此，作者在(10)中添加了参数$\lambda$

$$ m^p(x_i,y) = onehot[argmax_j softmax(\frac{\Phi_y^p \Phi_{x_i}^{p\top} + g_{ij}}{\lambda})] (11)$$

当$\lambda$较大时，映射矩阵$m^p$会变得平滑，当$\lambda$趋近于0时，映射会接近于二进制矩阵。想要选择一个满足所有 (x,y) 的$\lambda$是很困难的，相反，我们需要$\lambda$能够自适应地自动提取每对点云的最佳对齐。因此，这里使用一个小型网络$\Theta$来预测$\lambda$。这里让$\lambda = \Theta(\Psi_x^p,\Psi_y^p)$，其中，$\Psi_x^p = avg_i\Phi_{x_i}^p$，$\Psi_y^p = avg_i\Phi_{y_i}^p$。这个过程可以与强化学习中的Actor-Critor类似，Actor输出刚性动作，Critor输出预测的$\lambda$

***损失函数*** 最终的损失函数是多个$L_p$的总和，$L_p$由三项组成：刚性运动损失$L_p^m$、循环一致性损失$L_p^c$一个全局特征对齐损失$L_g$。此外作者还引入了一个折扣引子$\gamma < 1$，用来促进前几次通过PRNet的对齐。在训练期间，每个输入通过PRNet P次，综上所述：
$$ L = \sum_{p=1}^{P}\gamma^{p-1}L_p $$
其中，
$$ L_p = L_p^m + \alpha L_p^c + \beta L_g^p $$
刚性运动损失$L_p^m$为：
$$ L_p^m = || R_{xy}^{p\top}R_{xy}^{p*} - I ||^2 + || t_{xy}^p - t_{xy}^{p*} ||^2 $$
循环一致性损失为：
$$ L_p^c = || R_{xy}^{p}R_{yx}^{p} - I ||^2 + || t_{xy}^p - t_{yx}^{p} ||^2 $$
全局特征对齐损失为：
$$ L_g^p = || \Psi_x^p - \Psi_y^p || $$
全局特征对齐损失也为确定$\lambda$提供了信号，当两个形状在全局特征空间中接近时，$\lambda$应该较小，从而产生清晰的匹配矩阵，当两个形状差距较大时，$\lambda$增大，映射变得模糊。

## 四、实验

### 4.1ModelNet40上的部分到部分配准

ModelNet40由12311个CAD模型，包含40个对象类别。其中9843个用于训练，2468个用于测试。对CAD模型曲面上的最远点进行采样得到点云，每个点云包含1024个点。沿着每条轴，作者随机绘制一个刚性变换，沿每个轴旋转[0, 45°]，平移[-0.5, 0.5]，将刚性变换应用于x得到y。接着在空间中随机放一个点，并分别计算x，y中离它最近的768个点来模拟x和y的部分扫描。
